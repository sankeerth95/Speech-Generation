{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('./roast.zip')\n",
    "zip_ref.extractall('./')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ''\n",
    "for file in os.listdir('./roast'):\n",
    "    fp = open('./roast/' + file, 'r')\n",
    "    z = json.load(fp)\n",
    "    sentences = list(z.values())[0]\n",
    "    for s in sentences:\n",
    "        corpus += s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filtered = re.sub('[^a-z0-9A-Z\\s]', ' ', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filtered = re.sub('\\'', '', corpus_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filtered = corpus_filtered.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filtered = re.sub('\\s+', ' ', corpus_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = corpus_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2c = list(set(data))\n",
    "c2id = {c:i for i,c in enumerate(id2c)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(string_in):\n",
    "    return np.array([c2id[c] for c in string_in])\n",
    "\n",
    "def decode_string(encoded_str):\n",
    "    return ''.join([id2c[c] for c in encoded_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_length = 20\n",
    "vocab_size = len(id2c)\n",
    "data_size = len(data)\n",
    "\n",
    "i_size = vocab_size\n",
    "hidden_state_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, index_list, seq_length=seq_length, data_size=data_size):\n",
    "    batch = []\n",
    "    y = []\n",
    "    for i in index_list:\n",
    "        start = i%data_size\n",
    "        end = (i + seq_length)%data_size\n",
    "        if(end - start == seq_length):\n",
    "            batch.append(encode_string(X[start:end]))\n",
    "            y.append(encode_string(X[start+1:end+1]))\n",
    "        else:\n",
    "            batch.append(encode_string(X[start:]+X[:end]))\n",
    "            y.append(encode_string(X[start+1:]+X[:end+1]))            \n",
    "            \n",
    "    return np.array(batch), np.array(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ii = tf.Variable(tf.random.truncated_normal([i_size, hidden_state_size]))\n",
    "w_io = tf.Variable(tf.random.truncated_normal([hidden_state_size, hidden_state_size]))\n",
    "b_i = tf.Variable(tf.random.truncated_normal([hidden_state_size]))\n",
    "\n",
    "w_oi = tf.Variable(tf.random.truncated_normal([i_size, hidden_state_size]))\n",
    "w_oo = tf.Variable(tf.random.truncated_normal([hidden_state_size, hidden_state_size]))\n",
    "b_o = tf.Variable(tf.random.truncated_normal([hidden_state_size]))\n",
    "\n",
    "w_mi = tf.Variable(tf.random.truncated_normal([i_size, hidden_state_size]))\n",
    "w_mo = tf.Variable(tf.random.truncated_normal([hidden_state_size, hidden_state_size]))\n",
    "b_m = tf.Variable(tf.random.truncated_normal([hidden_state_size]))\n",
    "\n",
    "w_fi = tf.Variable(tf.random.truncated_normal([i_size, hidden_state_size]))\n",
    "w_fo = tf.Variable(tf.random.truncated_normal([hidden_state_size, hidden_state_size]))\n",
    "b_f = tf.Variable(tf.random.truncated_normal([hidden_state_size]))    \n",
    "    \n",
    "w_out = tf.Variable(tf.random.truncated_normal([hidden_state_size, vocab_size]))\n",
    "b_out = tf.Variable(tf.random.truncated_normal([vocab_size])) \n",
    "\n",
    "def lstm_cell(i, o, state):\n",
    "    input_gate = tf.sigmoid(i @ w_ii + o @ w_io  + b_i);\n",
    "    output_gate = tf.sigmoid(i @ w_oi + o @ w_oo + b_o);\n",
    "    forget_gate = tf.sigmoid(i @ w_fi + o @ w_fo + b_f);\n",
    "    memory_gate = tf.tanh(i @ w_mi + o @ w_mo + b_m);\n",
    "\n",
    "    state = forget_gate * state + input_gate * memory_gate \n",
    "    output = output_gate * tf.tanh(state)\n",
    "\n",
    "    return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train network\n",
    "#X = tf.placeholder(tf.int64, [batch_size, seq_length])\n",
    "#y = tf.placeholder(tf.int64, [batch_size, seq_length])\n",
    "\n",
    "def get_probabilities_logits(X):\n",
    "    encoded_X = tf.one_hot(X, vocab_size, axis=-1)\n",
    "    output_sequence = []\n",
    "\n",
    "    h_prev = tf.zeros([X.shape[0], hidden_state_size])\n",
    "    o_tprev = tf.zeros([X.shape[0], hidden_state_size])\n",
    "    \n",
    "    for t in range(X.shape[1]):\n",
    "        x_t = encoded_X[:, t, :]  # column t\n",
    "        o_tnext, h_next = lstm_cell(x_t, o_tprev, h_prev)\n",
    "        o_tprev = o_tnext#tf.argmax(probabs_next)\n",
    "        h_prev = h_next\n",
    "        output_sequence.append(o_tnext)\n",
    "        \n",
    "    chars_output = tf.reshape(output_sequence, shape=[-1, hidden_state_size]) @ w_out + b_out\n",
    "    chars_output = tf.reshape(chars_output, shape=[X.shape[1], X.shape[0], -1])\n",
    "    chars_output = tf.transpose(chars_output, perm=[1, 0, 2])\n",
    "#    print(chars_output) \n",
    "    return chars_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
