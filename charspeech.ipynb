{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample text: it is to be read from file system later on... dataset is supposed to have ~ 1 mil. characters\n",
    "text = open('./corpus/corpus.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some preprocessing required...\n",
    "#like take out the capitals, do something with the fullstops, indents, quotes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set(text))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = { c:i for i,c in enumerate(chars) }\n",
    "index_to_char = { i:c for i,c in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(char_string):\n",
    "    sentence = np.empty([0, len(chars)])\n",
    "    for char in char_string:\n",
    "        vector = np.zeros((1, len(chars)))\n",
    "        vector[0][char_to_index[char]] = 1\n",
    "        sentence = np.append(sentence, vector, axis=0)\n",
    "    return sentence\n",
    "\n",
    "def one_hot_char(char):\n",
    "    vector = np.zeros(len(chars))\n",
    "    vector[char_to_index[char]] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset X and y\n",
    "chars_per_sequence = 50\n",
    "skip = 2\n",
    "\n",
    "#X = np.empty([0, chars_per_sequence, len(chars)])\n",
    "X_train = []\n",
    "end_char = []\n",
    "for i in range(0, len(text) - chars_per_sequence-1, skip):\n",
    "    X_train.append(one_hot(text[i:i+chars_per_sequence]))\n",
    "    end_char.append(one_hot_char(text[i+chars_per_sequence]))\n",
    "X_train = np.array(X_train)\n",
    "end_char = np.array(end_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model parameters\n",
    "\n",
    "hidden_state_size = 1024\n",
    "state_size = 512\n",
    "i_size = vocab_size\n",
    "o_size = vocab_size\n",
    "\n",
    "\n",
    "batch_size = 42\n",
    "sequence_length = chars_per_sequence#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## construct model graph and rout inputs, outputs\n",
    "# prefixing the None of the batch size...\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    w_ii = tf.Variable(tf.random.truncated_normal([i_size, hidden_state_size]))\n",
    "    w_io = tf.Variable(tf.random.truncated_normal([hidden_state_size, hidden_state_size]))\n",
    "    b_i = tf.Variable(tf.random.truncated_normal([hidden_state_size]))\n",
    "    \n",
    "    w_oi = tf.Variable(tf.random.truncated_normal([i_size, hidden_state_size]))\n",
    "    w_oo = tf.Variable(tf.random.truncated_normal([hidden_state_size, hidden_state_size]))\n",
    "    b_o = tf.Variable(tf.random.truncated_normal([hidden_state_size]))\n",
    "\n",
    "    w_mi = tf.Variable(tf.random.truncated_normal([i_size, hidden_state_size]))\n",
    "    w_mo = tf.Variable(tf.random.truncated_normal([hidden_state_size, hidden_state_size]))\n",
    "    b_m = tf.Variable(tf.random.truncated_normal([hidden_state_size]))\n",
    "    \n",
    "    w_fi = tf.Variable(tf.random.truncated_normal([i_size, hidden_state_size]))\n",
    "    w_fo = tf.Variable(tf.random.truncated_normal([hidden_state_size, hidden_state_size]))\n",
    "    b_f = tf.Variable(tf.random.truncated_normal([hidden_state_size]))    \n",
    "    \n",
    "    w_out = tf.Variable(tf.random.truncated_normal([hidden_state_size, vocab_size]))\n",
    "    b_out = tf.Variable(tf.random.truncated_normal([vocab_size])) \n",
    "    \n",
    "    def lstm_cell(i, o, state):\n",
    "        input_gate = tf.sigmoid(i @ w_ii + o @ w_io  + b_i);\n",
    "        output_gate = tf.sigmoid(i @ w_oi + o @ w_oo + b_o);\n",
    "        forget_gate = tf.sigmoid(i @ w_fi + o @ w_fo + b_f);\n",
    "        memory_gate = tf.tanh(i @ w_mi + o @ w_mo + b_m);\n",
    "        \n",
    "        state = forget_gate * state + input_gate * memory_gate \n",
    "        output = output_gate * tf.tanh(state)\n",
    "        \n",
    "        return output, state\n",
    "\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[batch_size, sequence_length, vocab_size])\n",
    "    last_char = tf.placeholder(dtype=tf.float32, shape=[batch_size, vocab_size])\n",
    "\n",
    "    output_sequence = []\n",
    "    y = []\n",
    "\n",
    "    state = tf.Variable(tf.zeros([batch_size, hidden_state_size]))\n",
    "    o_vector = tf.Variable(tf.zeros([batch_size, hidden_state_size]))\n",
    "\n",
    "    for i in range(sequence_length):\n",
    "        o_vector, state = lstm_cell(X[:, i, :], o_vector, state)\n",
    "        output_sequence.append(o_vector)\n",
    "        if i < sequence_length-1:\n",
    "            y.append(X[:, i+1, :]) \n",
    "        else:\n",
    "            y.append(last_char)\n",
    "    output_sequence = tf.stack(output_sequence, axis=1)\n",
    "    y = tf.stack(y, axis=1)\n",
    "    \n",
    "    chars_output = tf.reshape(output_sequence, shape=[-1, hidden_state_size]) @ w_out + b_out\n",
    "    chars_output = tf.reshape(chars_output, shape=[batch_size, sequence_length, vocab_size])\n",
    "    \n",
    "    \n",
    "    loss = sequence_length*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=chars_output, labels=y) )\n",
    "\n",
    "    #optimizer = tf.train.AdamOptimizer()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "    step = optimizer.minimize(loss)\n",
    "    \n",
    "    \n",
    "    #generate text character by character:\n",
    "    o_vector_test = tf.placeholder(dtype=tf.float32, shape=[hidden_state_size])\n",
    "    state_test = tf.placeholder(dtype=tf.float32, shape=[hidden_state_size])\n",
    "    x_test = tf.placeholder(dtype=tf.float32, shape=[vocab_size])\n",
    "    o_vector_test_out, state_test_out = lstm_cell(tf.reshape(x_test, shape=[1, -1]), tf.reshape(o_vector_test, shape=[1, -1]), state_test)\n",
    "    output_char_test = tf.argmax(state_test_out @ w_out + b_out, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1081.3002\n",
      "10 996.949\n",
      "20 883.97076\n",
      "30 770.5477\n",
      "40 712.9703\n",
      "50 684.7426\n",
      "60 681.9686\n",
      "70 664.63934\n",
      "80 661.029\n",
      "90 624.83167\n",
      "100 623.3298\n",
      "110 645.6527\n",
      "120 641.8442\n",
      "130 649.7263\n",
      "140 654.1144\n",
      "150 640.8444\n",
      "160 634.3124\n",
      "170 624.72095\n",
      "180 589.7375\n",
      "190 595.03534\n",
      "200 575.44415\n",
      "210 582.74817\n",
      "220 592.5355\n",
      "230 610.99536\n",
      "240 624.6385\n",
      "250 621.167\n",
      "260 626.63434\n",
      "270 617.5976\n",
      "280 600.82605\n",
      "290 599.416\n",
      "300 603.4523\n",
      "310 607.79456\n",
      "320 633.5041\n",
      "330 604.64\n",
      "340 591.89484\n",
      "350 583.9649\n",
      "360 594.98096\n",
      "370 597.11127\n",
      "380 584.3137\n",
      "390 576.55426\n",
      "400 548.5362\n",
      "410 542.6016\n",
      "420 539.61743\n",
      "430 535.68097\n",
      "440 541.1704\n",
      "450 545.51886\n",
      "460 544.907\n",
      "470 545.02344\n",
      "480 542.2078\n",
      "490 566.48755\n",
      "500 551.5916\n",
      "510 542.8602\n",
      "520 539.93976\n",
      "530 507.38763\n",
      "540 506.52185\n",
      "550 502.51965\n",
      "560 509.30118\n",
      "570 510.08987\n",
      "580 501.45847\n",
      "590 507.28693\n",
      "600 493.88104\n",
      "610 502.1738\n",
      "620 513.8662\n",
      "630 514.1284\n",
      "640 506.58264\n",
      "650 519.37616\n",
      "660 498.40887\n",
      "670 487.97446\n",
      "680 463.6243\n",
      "690 445.2973\n",
      "700 455.08752\n",
      "710 459.8486\n",
      "720 451.32352\n",
      "730 486.50082\n",
      "740 509.41534\n",
      "750 520.04486\n",
      "760 515.0587\n",
      "770 515.6147\n",
      "780 518.32996\n",
      "790 493.825\n",
      "800 493.45154\n",
      "810 511.7925\n",
      "820 522.5258\n",
      "830 521.29193\n",
      "840 510.74677\n",
      "850 502.96072\n",
      "860 505.3594\n",
      "870 496.77463\n",
      "880 484.56927\n",
      "890 478.989\n",
      "900 465.82904\n",
      "910 457.44968\n",
      "920 449.7763\n",
      "930 438.7526\n",
      "940 452.28934\n",
      "950 444.30264\n",
      "960 444.36646\n",
      "970 444.99265\n",
      "980 458.14642\n",
      "990 460.0049\n"
     ]
    }
   ],
   "source": [
    "gpuconfig = tf.GPUOptions(per_process_gpu_memory_fraction=0.33)\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(gpu_options=gpuconfig)) as sess:\n",
    "    offs = 0\n",
    "    max_steps = 1000\n",
    "    saver = tf.train.Saver()\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(max_steps):\n",
    "        si = (i+offs)%X_train.shape[0]\n",
    "        if si+batch_size < X_train.shape[0]:\n",
    "            X_batch = X_train[si:si+batch_size]\n",
    "            end_char_batch = end_char[si:si+batch_size]\n",
    "        else:\n",
    "            offs_new = (si+batch_size)%X_train.shape[0]\n",
    "            X_batch = np.concatenate([X_train[si:], X_train[:offs_new]])\n",
    "            end_char_batch = np.concatenate([end_char[si:], end_char[:offs_new]])\n",
    "            #offs = offs_new\n",
    "        \n",
    "        k = sess.run(step, { X: X_batch, last_char: end_char_batch})\n",
    "        if(i%10 == 0):\n",
    "            print(i, sess.run(loss, { X: X_batch, last_char: end_char_batch}))\n",
    "    saver.save(sess, './model/model.ckpt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session(graph=graph) as sess:\n",
    "#    model = tf.train.load_checkpoint('./model/model.ckpt')\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model/model.ckpt')\n",
    "    z = ['a', np.zeros([hidden_state_size]), np.zeros([hidden_state_size])]\n",
    "\n",
    "    \n",
    "    output_string = z[0]\n",
    "    for i in range(20):\n",
    "        z = sess.run([output_char_test,o_vector_test_out, state_test_out], {x_test: one_hot_char(z[0]), o_vector_test: z[1],\\\n",
    "                                                                        state_test: z[2] } )\n",
    "    \n",
    "        z[0] = index_to_char[z[0][0]]\n",
    "        z[1], z[2] = z[1][0], z[2][0]\n",
    "\n",
    "        output_string += z[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adeseeemmmmsslldldldl'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
